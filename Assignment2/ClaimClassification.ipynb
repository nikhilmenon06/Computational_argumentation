{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics,naive_bayes\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the training data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = 'train-data-prepared.json'\n",
    "val_data_file = 'val-data-prepared.json'\n",
    "\n",
    "df_train = pd.read_json(train_data_file)\n",
    "df_val = pd.read_json(val_data_file)\n",
    "# display(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Pre-process the text(lower casing, lead/train space stripping,remove punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PreprocessData(df):\n",
    "    df['clean_text'] = df['text'].str.lower()\n",
    "    df['clean_text'] = df['clean_text'].str.strip()\n",
    "    df['clean_text'] = df['clean_text'].str.replace('[^?\\w\\s]','')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureExtract(df):\n",
    "    \n",
    "    df['token_count'] = df['clean_text'].apply(lambda x: len(nlp(x)))\n",
    "\n",
    "    md_exist_list = [] # modal verb\n",
    "    verb_count_list = [] # verb\n",
    "    prp_exist_list = [] # personal pronouns\n",
    "    vbp_exist_list = [] # verb non 3rd person\n",
    "    adv_exist_list = [] # adverb\n",
    "    conj_exist_list = [] #conjunction/preposition\n",
    "    adj_exist_list = [] #adjective\n",
    "    disc_exist_list = [] # discourse markers\n",
    "    question_list = [] # question text\n",
    "\n",
    "    for text in df['clean_text']:\n",
    "        doc = nlp(text)\n",
    "        md_exist = 0\n",
    "        verb_count = 0\n",
    "        prp_exist = 0\n",
    "        vbp_exist = 0\n",
    "        adv_exist = 0\n",
    "        conj_exist = 0\n",
    "        adj_exist = 0\n",
    "        disc_exist = 0\n",
    "        question = 0\n",
    "\n",
    "        for token in doc:\n",
    "            if token.tag_ == 'MD':\n",
    "                md_exist = 1\n",
    "\n",
    "            if token.pos_ == 'VERB':\n",
    "                verb_count = 1\n",
    "\n",
    "            if token.tag_ == 'PRP':\n",
    "                prp_exist = 1\n",
    "\n",
    "            if token.tag_ == 'VBP':\n",
    "                vbp_exist = 1\n",
    "\n",
    "            if token.pos_ == 'ADV':\n",
    "                adv_exist = 1\n",
    "            \n",
    "            if token.dep_ == 'prep':\n",
    "                conj_exist = 1\n",
    "            \n",
    "            if token.pos_ == 'ADJ':\n",
    "                adj_exist = 1\n",
    "            \n",
    "            if token.tag_ == 'IN' and token.pos_!='ADP':\n",
    "                disc_exist = 1\n",
    "            \n",
    "            if token.text == '?':\n",
    "                question = 1\n",
    "\n",
    "        md_exist_list.append(md_exist)\n",
    "        verb_count_list.append(verb_count)\n",
    "        prp_exist_list.append(prp_exist)\n",
    "        vbp_exist_list.append(vbp_exist)\n",
    "        adv_exist_list.append(adv_exist)\n",
    "        conj_exist_list.append(conj_exist)\n",
    "        adj_exist_list.append(adj_exist)\n",
    "        disc_exist_list.append(disc_exist)\n",
    "        question_list.append(question)\n",
    "\n",
    "    df['modal_exist'] = md_exist_list\n",
    "    df['verb_count'] = verb_count_list\n",
    "    df['prp_exist'] = prp_exist_list\n",
    "    df['vbp_exist'] = vbp_exist_list\n",
    "    df['adv_exist'] = adv_exist_list\n",
    "    df['conj_exist'] = conj_exist_list\n",
    "    df['adj_exist'] = adj_exist_list\n",
    "    df['disc_exist'] = disc_exist_list\n",
    "    df['question'] = question_list\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess and feature extraction: Train and Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = PreprocessData(df_train)\n",
    "df_train = FeatureExtract(df_train)\n",
    "\n",
    "df_val = PreprocessData(df_val)\n",
    "df_val = FeatureExtract(df_val)\n",
    "# display(df_train)\n",
    "# print(\"next \\n\")\n",
    "# display(df_val)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this code is for analying the features. Uncomment the second line to test different features\n",
    "\n",
    "# display(df_train)\n",
    "# df_train.loc[(df_train['adv_exist'] != 0) & (df_train['label'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>token_count</th>\n",
       "      <th>modal_exist</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>prp_exist</th>\n",
       "      <th>vbp_exist</th>\n",
       "      <th>adv_exist</th>\n",
       "      <th>conj_exist</th>\n",
       "      <th>adj_exist</th>\n",
       "      <th>disc_exist</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1363ac6f16e232a1d8e9343d975ebe10</td>\n",
       "      <td>Since communism has been relegated to just a h...</td>\n",
       "      <td>0</td>\n",
       "      <td>since communism has been relegated to just a h...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6b925ce5eeb8b690b35972abafcb7c60</td>\n",
       "      <td>Can you counter that?</td>\n",
       "      <td>0</td>\n",
       "      <td>can you counter that?</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99977c6e63734add1c1b600be79b3342</td>\n",
       "      <td>Censorship does not eliminate the censored ind...</td>\n",
       "      <td>0</td>\n",
       "      <td>censorship does not eliminate the censored ind...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7e34d9e198bc9e12f0868793c68d32f0</td>\n",
       "      <td>Without the extra population from abortions, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>without the extra population from abortions ha...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629d09668c3339dba831f6c81a307b0e</td>\n",
       "      <td>I can't stand it</td>\n",
       "      <td>1</td>\n",
       "      <td>i cant stand it</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cd07a9b7ff61a13ca450f37f61416885</td>\n",
       "      <td>This is much more important than it's faithful...</td>\n",
       "      <td>1</td>\n",
       "      <td>this is much more important than its faithfuln...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99be8d453162bd56e93c932640600d8f</td>\n",
       "      <td>Every thought stands of its own individual mer...</td>\n",
       "      <td>0</td>\n",
       "      <td>every thought stands of its own individual merits</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38763fbb689db60dcbb8adbc97fa1903</td>\n",
       "      <td>you don't have to necessarily think you're bet...</td>\n",
       "      <td>0</td>\n",
       "      <td>you dont have to necessarily think youre bette...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>68244b723d41f2fe4a6d475e7dee585e</td>\n",
       "      <td>You don't understand the signals you're sendin...</td>\n",
       "      <td>1</td>\n",
       "      <td>you dont understand the signals youre sending ...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0867cb40fc364af10304cb962558d75e</td>\n",
       "      <td>neighbors went out but no one had the head to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>neighbors went out but no one had the head to ...</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66848721456b313c07bdace62141c3d5</td>\n",
       "      <td>All of these are terrible options, and there a...</td>\n",
       "      <td>0</td>\n",
       "      <td>all of these are terrible options and there ar...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bf43ec7553984de758fa1e26896607ae</td>\n",
       "      <td>you've altered it in such a way that I now fee...</td>\n",
       "      <td>1</td>\n",
       "      <td>youve altered it in such a way that i now feel...</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6897742dcaae4613b191b588c1eeed04</td>\n",
       "      <td>May as well enjoy life while you temporarily e...</td>\n",
       "      <td>0</td>\n",
       "      <td>may as well enjoy life while you temporarily e...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>c0589ee894b97bd9446216eeba8d63cd</td>\n",
       "      <td>Really though.</td>\n",
       "      <td>0</td>\n",
       "      <td>really though</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3f1c5eb463a9a0ec84aee55db345802f</td>\n",
       "      <td>I wonder how you've make such good friends and...</td>\n",
       "      <td>1</td>\n",
       "      <td>i wonder how youve make such good friends and ...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>d5b2cf263e246a8ebb6a55dd500b970a</td>\n",
       "      <td>If so, how big are we talking?</td>\n",
       "      <td>0</td>\n",
       "      <td>if so how big are we talking?</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cf0156cccee7cf61bac78a6e204c2b34</td>\n",
       "      <td>More importantly though,</td>\n",
       "      <td>0</td>\n",
       "      <td>more importantly though</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>71dc7727d6f9735e276f27afbbce2cab</td>\n",
       "      <td>It is also downright silly to consider</td>\n",
       "      <td>1</td>\n",
       "      <td>it is also downright silly to consider</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b1ba846fa728f4f9b027cfa6a3888266</td>\n",
       "      <td>once that religion is established as the capit...</td>\n",
       "      <td>1</td>\n",
       "      <td>once that religion is established as the capit...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>61a6d7a3dbcf11b93dd70f71221856a9</td>\n",
       "      <td>really it is the citizens that have the belief...</td>\n",
       "      <td>1</td>\n",
       "      <td>really it is the citizens that have the belief...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0   1363ac6f16e232a1d8e9343d975ebe10   \n",
       "1   6b925ce5eeb8b690b35972abafcb7c60   \n",
       "2   99977c6e63734add1c1b600be79b3342   \n",
       "3   7e34d9e198bc9e12f0868793c68d32f0   \n",
       "4   629d09668c3339dba831f6c81a307b0e   \n",
       "5   cd07a9b7ff61a13ca450f37f61416885   \n",
       "6   99be8d453162bd56e93c932640600d8f   \n",
       "7   38763fbb689db60dcbb8adbc97fa1903   \n",
       "8   68244b723d41f2fe4a6d475e7dee585e   \n",
       "9   0867cb40fc364af10304cb962558d75e   \n",
       "10  66848721456b313c07bdace62141c3d5   \n",
       "11  bf43ec7553984de758fa1e26896607ae   \n",
       "12  6897742dcaae4613b191b588c1eeed04   \n",
       "13  c0589ee894b97bd9446216eeba8d63cd   \n",
       "14  3f1c5eb463a9a0ec84aee55db345802f   \n",
       "15  d5b2cf263e246a8ebb6a55dd500b970a   \n",
       "16  cf0156cccee7cf61bac78a6e204c2b34   \n",
       "17  71dc7727d6f9735e276f27afbbce2cab   \n",
       "18  b1ba846fa728f4f9b027cfa6a3888266   \n",
       "19  61a6d7a3dbcf11b93dd70f71221856a9   \n",
       "\n",
       "                                                 text  label  \\\n",
       "0   Since communism has been relegated to just a h...      0   \n",
       "1                               Can you counter that?      0   \n",
       "2   Censorship does not eliminate the censored ind...      0   \n",
       "3   Without the extra population from abortions, h...      0   \n",
       "4                                    I can't stand it      1   \n",
       "5   This is much more important than it's faithful...      1   \n",
       "6   Every thought stands of its own individual mer...      0   \n",
       "7   you don't have to necessarily think you're bet...      0   \n",
       "8   You don't understand the signals you're sendin...      1   \n",
       "9   neighbors went out but no one had the head to ...      0   \n",
       "10  All of these are terrible options, and there a...      0   \n",
       "11  you've altered it in such a way that I now fee...      1   \n",
       "12  May as well enjoy life while you temporarily e...      0   \n",
       "13                                     Really though.      0   \n",
       "14  I wonder how you've make such good friends and...      1   \n",
       "15                     If so, how big are we talking?      0   \n",
       "16                          More importantly though,       0   \n",
       "17             It is also downright silly to consider      1   \n",
       "18  once that religion is established as the capit...      1   \n",
       "19  really it is the citizens that have the belief...      1   \n",
       "\n",
       "                                           clean_text  token_count  \\\n",
       "0   since communism has been relegated to just a h...           11   \n",
       "1                               can you counter that?            5   \n",
       "2   censorship does not eliminate the censored ind...            7   \n",
       "3   without the extra population from abortions ha...           38   \n",
       "4                                     i cant stand it            5   \n",
       "5   this is much more important than its faithfuln...           12   \n",
       "6   every thought stands of its own individual merits            8   \n",
       "7   you dont have to necessarily think youre bette...           18   \n",
       "8   you dont understand the signals youre sending ...           28   \n",
       "9   neighbors went out but no one had the head to ...           47   \n",
       "10  all of these are terrible options and there ar...           13   \n",
       "11  youve altered it in such a way that i now feel...           27   \n",
       "12  may as well enjoy life while you temporarily e...            9   \n",
       "13                                      really though            2   \n",
       "14  i wonder how youve make such good friends and ...           21   \n",
       "15                      if so how big are we talking?            8   \n",
       "16                            more importantly though            3   \n",
       "17             it is also downright silly to consider            7   \n",
       "18  once that religion is established as the capit...           24   \n",
       "19  really it is the citizens that have the belief...           28   \n",
       "\n",
       "    modal_exist  verb_count  prp_exist  vbp_exist  adv_exist  conj_exist  \\\n",
       "0             0           1          0          0          1           1   \n",
       "1             1           1          1          0          0           0   \n",
       "2             0           1          0          0          1           0   \n",
       "3             0           1          0          1          1           1   \n",
       "4             1           1          1          0          1           0   \n",
       "5             0           1          0          0          1           1   \n",
       "6             0           1          0          0          0           1   \n",
       "7             0           1          1          1          1           1   \n",
       "8             0           1          1          1          1           1   \n",
       "9             0           1          1          1          1           1   \n",
       "10            0           1          0          1          1           1   \n",
       "11            0           1          1          1          1           1   \n",
       "12            1           1          1          1          1           0   \n",
       "13            0           0          0          0          1           0   \n",
       "14            0           1          1          1          1           1   \n",
       "15            0           1          1          1          1           0   \n",
       "16            0           0          0          0          1           0   \n",
       "17            0           1          1          0          1           0   \n",
       "18            0           1          0          0          1           1   \n",
       "19            0           1          1          1          1           1   \n",
       "\n",
       "    adj_exist  disc_exist  question  \n",
       "0           0           0         0  \n",
       "1           0           0         1  \n",
       "2           0           0         0  \n",
       "3           1           0         0  \n",
       "4           0           0         0  \n",
       "5           1           0         0  \n",
       "6           1           0         0  \n",
       "7           1           0         0  \n",
       "8           1           0         0  \n",
       "9           0           0         0  \n",
       "10          1           0         0  \n",
       "11          1           0         0  \n",
       "12          0           0         0  \n",
       "13          0           0         0  \n",
       "14          1           0         0  \n",
       "15          1           0         1  \n",
       "16          0           0         0  \n",
       "17          1           0         0  \n",
       "18          0           0         0  \n",
       "19          1           0         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(20)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this part contains junk code for testing\n",
    "\n",
    "text = \"him personally believe had would feel death penalty should be abolished plays\"\n",
    "doc1 = nlp(text)\n",
    "md_count = 0\n",
    "for token in doc1:\n",
    "    print(token.pos_, token.tag_)\n",
    "    if token.tag_ == 'MD':\n",
    "        md_count = md_count + 1\n",
    "\n",
    "print(md_count)\n",
    "\n",
    "spacy.explain('VBG')\n",
    "\n",
    "# junk code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction using Bag of Words(uni and bigrams): Train and Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2619, 28021)\n",
      "(2619,)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "feature_matrix_bow = vectorizer.fit_transform(df_train['clean_text'])\n",
    "\n",
    "\n",
    "df_features_bow = pd.DataFrame(feature_matrix_bow.toarray())\n",
    "# df_features_text = df_train[[\"token_count\",\"modal_exist\",\"verb_count\",\"prp_exist\",\"vbp_exist\",\"adv_exist\"]]\n",
    "df_features_text = df_train[[\"modal_exist\",\"verb_count\",\"prp_exist\",\"vbp_exist\",\"adv_exist\",\"conj_exist\",\"adj_exist\",\n",
    "                             \"disc_exist\"]]\n",
    "df_features = pd.concat([df_features_bow,df_features_text],axis = 1)\n",
    "\n",
    "x_train = df_features.values\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "# display(df_features)\n",
    "# print(feature_matrix_bow.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 28021)\n",
      "(349,)\n"
     ]
    }
   ],
   "source": [
    "# Transforming the Val/Test dataset with the vectorizer object\n",
    "\n",
    "feature_matrix_bow_val = vectorizer.transform(df_val['clean_text'])\n",
    "\n",
    "df_features_bow_val = pd.DataFrame(feature_matrix_bow_val.toarray())\n",
    "# df_features_text_val = df_val[[\"token_count\",\"modal_exist\",\"verb_count\",\"prp_exist\",\"vbp_exist\",\"adv_exist\"]]\n",
    "df_features_text_val = df_val[[\"modal_exist\",\"verb_count\",\"prp_exist\",\"vbp_exist\",\"adv_exist\",\"conj_exist\",\"adj_exist\",\n",
    "                              \"disc_exist\"]]\n",
    "df_features_val = pd.concat([df_features_bow_val,df_features_text_val],axis = 1)\n",
    "\n",
    "x_val = df_features_val.values\n",
    "y_val = df_val['label'].values\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifer training and predict: Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_space = np.logspace(-5, 8, 15)\n",
    "# param_grid = {'C': c_space, 'penalty':['l2']}\n",
    "\n",
    "# classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "# classifier_CV = GridSearchCV(classifier, param_grid, cv=5)\n",
    "# classifier_CV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch (you dont have to run this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'C':[1.0, 10.0, 100.0],'gamma':[0.1, 0.01]}\n",
    "# classifier = SVC()\n",
    "\n",
    "# classifier_CV=GridSearchCV(classifier, parameters, cv=3)\n",
    "# classifier_CV.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = classifier_CV.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.f1_score(y_val,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual training with the best hyperparameters combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(C=10.0, gamma=0.01)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5042735042735041"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_val,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting IDs -> Generating a dictionary -> Creating a JSON output file with predictions\n",
    "\n",
    "val_data_id = df_val['id'].values\n",
    "pred_val = dict(zip(val_data_id, predictions))\n",
    "\n",
    "with open('pred_out.json', 'w') as fp:\n",
    "    json.dump(pred_val,fp,default=str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
