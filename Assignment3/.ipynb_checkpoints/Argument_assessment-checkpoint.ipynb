{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HKRgCtldjF17"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import json\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense,LSTM,Embedding,InputLayer,Concatenate\n",
    "# from tensorflow.keras import Model\n",
    "# from sklearn import metrics\n",
    "# import keras\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3-pRx3tZu84V"
   },
   "outputs": [],
   "source": [
    "def PreprocessData(df):\n",
    "  df['clean_text'] = df['_body'].str.lower()\n",
    "  df['clean_text'] = df['clean_text'].str.replace('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ')\n",
    "  df['clean_text'] = df['clean_text'].str.strip()\n",
    "  df['clean_text'] = df['clean_text'].str.replace('[^\\w\\s]','')\n",
    "  return df\n",
    "\n",
    "def ConcatenatePost(df):\n",
    "  df['clean_text_copy'] = df.groupby(['id'])['clean_text'].transform(lambda x : ' '.join(x))\n",
    "  df['clean_text'] = df.groupby(['id'])['clean_text'].transform(lambda x : '||'.join(x))\n",
    "  df['_body'] = df.groupby(['id'])['_body'].transform(lambda x : '|'.join(x))\n",
    "  df['label'] = df.groupby(['id'])['label'].transform('max')\n",
    "  df = df.drop_duplicates(inplace=False)\n",
    "  return df\n",
    "\n",
    "def FeatureExtract(df):\n",
    "\n",
    "  offensive_words = [\"ass\",\"idiot\",\"moron\",\"stupid\",\"bitch\",\"shit\",\"fuck\",\"dumb\",\"fool\",\"pussy\"]\n",
    "  advmod_exist_list = [] #intensifiers eg: absolutely, very, extremely, seriously etc\n",
    "  prp_exist_list = [] #personal pronouns eg: I, me, you etc\n",
    "  acomp_exist_list = [] #adjectivial complement eg: unreal, unsatisfactory, unwilling\n",
    "  relcl_exist_list = [] #eg: hurts, torutres, celebrates\n",
    "  abuse_exist_list = [] #bad and offensive words\n",
    "  for text in df['clean_text_copy']:\n",
    "    doc = nlp(text)\n",
    "    advmod_exist = 0\n",
    "    prp_exist = 0\n",
    "    acomp_exist = 0\n",
    "    relcl_exist = 0\n",
    "    abuse_exist = 0\n",
    "    for token in doc:\n",
    "      if token.dep_ == 'advmod':\n",
    "        advmod_exist = advmod_exist + 1\n",
    "      \n",
    "      if token.tag_ == 'PRP':\n",
    "        prp_exist = prp_exist + 1\n",
    "      \n",
    "      if token.pos_ == 'ADJ' and token.dep_ == 'acomp':\n",
    "        acomp_exist = acomp_exist + 1\n",
    "      \n",
    "      if token.text in offensive_words:\n",
    "        abuse_exist = abuse_exist + 1\n",
    "      \n",
    "      if token.dep_ == 'relcl':\n",
    "        relcl_exist = relcl_exist + 1\n",
    "    \n",
    "    advmod_exist_list.append(advmod_exist)\n",
    "    prp_exist_list.append(prp_exist)\n",
    "    acomp_exist_list.append(acomp_exist)\n",
    "    abuse_exist_list.append(abuse_exist)\n",
    "    relcl_exist_list.append(relcl_exist)\n",
    "  \n",
    "  df['intensifier'] = advmod_exist_list\n",
    "  df['prp'] = prp_exist_list\n",
    "  df['acomp'] = acomp_exist_list\n",
    "  df['abuse'] = abuse_exist_list\n",
    "  df['relcl'] = relcl_exist_list\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fNWk-REDjF18"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/train-data-prepared.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d8cb30def4aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mval_data_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/val-data-prepared.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mjson_data_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/train-data-prepared.json'"
     ]
    }
   ],
   "source": [
    "train_data_file = 'train-data-prepared.json'\n",
    "val_data_file = 'val-data-prepared.json'\n",
    "\n",
    "with open(train_data_file, 'r') as f:\n",
    "  json_data_train = json.load(f)\n",
    "\n",
    "with open(val_data_file, 'r') as f:\n",
    "  json_data_val = json.load(f)\n",
    "\n",
    "\n",
    "init_data_train = pd.json_normalize(json_data_train, record_path='preceding_posts',meta= ['id','label'],max_level=1, record_prefix='_')\n",
    "init_data_val = pd.json_normalize(json_data_val, record_path='preceding_posts',meta= ['id','label'],max_level=1, record_prefix='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SP8b6QAyF2Lc"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "id": "yzs7Q0NYjF18",
    "outputId": "06c928ff-87e5-440c-cb83-41684fb154d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t1_dggp3q9</td>\n",
       "      <td>...because it's illegal in our reality, vs. th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_dggp3q9</td>\n",
       "      <td>i live in a nation were it is completely legal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_dk3zd9h</td>\n",
       "      <td>Because making prostitution legal makes it ver...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_dk3zd9h</td>\n",
       "      <td>I'd be interested in reading up on this, do yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_d86bsqs</td>\n",
       "      <td>Why are you linking Wikipedia and not direct t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>t1_ch7503g</td>\n",
       "      <td>Wow thanks for the help.\\n\\nOne question, can ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>t1_denmvjy</td>\n",
       "      <td>Okay buddy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>t1_denmvjy</td>\n",
       "      <td>Shrug it off all you want, it's a simple fact....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>t1_crtmi2e</td>\n",
       "      <td>It is a thing, I'm not sure if it's universal ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>t1_crtmi2e</td>\n",
       "      <td>But when is it a thing? If you saw a police of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3872 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              _body label\n",
       "0     t1_dggp3q9  ...because it's illegal in our reality, vs. th...     1\n",
       "1     t1_dggp3q9  i live in a nation were it is completely legal...     1\n",
       "2     t1_dk3zd9h  Because making prostitution legal makes it ver...     0\n",
       "3     t1_dk3zd9h  I'd be interested in reading up on this, do yo...     0\n",
       "4     t1_d86bsqs  Why are you linking Wikipedia and not direct t...     1\n",
       "...          ...                                                ...   ...\n",
       "3867  t1_ch7503g  Wow thanks for the help.\\n\\nOne question, can ...     0\n",
       "3868  t1_denmvjy                                       Okay buddy.      1\n",
       "3869  t1_denmvjy  Shrug it off all you want, it's a simple fact....     1\n",
       "3870  t1_crtmi2e  It is a thing, I'm not sure if it's universal ...     0\n",
       "3871  t1_crtmi2e  But when is it a thing? If you saw a police of...     0\n",
       "\n",
       "[3872 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t1_dipwvtv</td>\n",
       "      <td>&gt;At this point it seems clear that we have ver...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t1_dipwvtv</td>\n",
       "      <td>&gt;This is a disgusting attitude that glorifies ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t1_dctegi4</td>\n",
       "      <td>The black community and LGBTQ rights is a grea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t1_dctegi4</td>\n",
       "      <td>Thank you for taking the time to share your pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_d4vri90</td>\n",
       "      <td>So what?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>t1_cpcigu7</td>\n",
       "      <td>But sexual harassment is also not a bathroom p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>t1_cnu1fi5</td>\n",
       "      <td>We think the government is this thing imposing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>t1_cnu1fi5</td>\n",
       "      <td>&gt;We think the government is this thing imposin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>t1_dhdub9z</td>\n",
       "      <td>Can you elaborate, what are \"gun free zones\" i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>t1_dhdub9z</td>\n",
       "      <td>&gt;Can you elaborate, what are \"gun free zones\" ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              _body label\n",
       "0    t1_dipwvtv  >At this point it seems clear that we have ver...     1\n",
       "1    t1_dipwvtv  >This is a disgusting attitude that glorifies ...     1\n",
       "2    t1_dctegi4  The black community and LGBTQ rights is a grea...     0\n",
       "3    t1_dctegi4  Thank you for taking the time to share your pe...     0\n",
       "4    t1_d4vri90                                          So what?      1\n",
       "..          ...                                                ...   ...\n",
       "511  t1_cpcigu7  But sexual harassment is also not a bathroom p...     0\n",
       "512  t1_cnu1fi5  We think the government is this thing imposing...     1\n",
       "513  t1_cnu1fi5  >We think the government is this thing imposin...     1\n",
       "514  t1_dhdub9z  Can you elaborate, what are \"gun free zones\" i...     0\n",
       "515  t1_dhdub9z  >Can you elaborate, what are \"gun free zones\" ...     0\n",
       "\n",
       "[516 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = init_data_train[['id','_body','label']]\n",
    "data_val = init_data_val[['id','_body','label']]\n",
    "display(data_train)\n",
    "display(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GV1UTAhQjF19",
    "outputId": "77005dbb-f54e-4c2c-d6e2-82e470114063"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "df_train = PreprocessData(data_train)\n",
    "df_val = PreprocessData(data_val)\n",
    "df_train = ConcatenatePost(df_train)\n",
    "df_val = ConcatenatePost(df_val)\n",
    "# delete later\n",
    "# display(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AzsHUeCzqGIe"
   },
   "outputs": [],
   "source": [
    "max_vocab = 2500\n",
    "tokenizer = Tokenizer(num_words = max_vocab,split = ' ', oov_token=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m5RfpMV4pSvA",
    "outputId": "29b7f62f-01d8-423d-c804-82b8b308723b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1936, 3033)\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(df_train['clean_text_copy'].values)\n",
    "x_train_neural =  tokenizer.texts_to_sequences(df_train['clean_text_copy'].values)\n",
    "x_val_neural = tokenizer.texts_to_sequences(df_val['clean_text_copy'])\n",
    "\n",
    "max_length = max(len(s.split()) for s in df_train['clean_text_copy'].values)\n",
    "x_train_neural = pad_sequences(x_train_neural,maxlen=max_length)\n",
    "x_val_neural = pad_sequences(x_val_neural,maxlen=max_length)\n",
    "\n",
    "y_train = df_train['label'].values\n",
    "y_val = df_val['label'].values\n",
    "\n",
    "print(x_train_neural.shape)\n",
    "# print(x_train_neural)\n",
    "\n",
    "# print(x_val_neural.shape)\n",
    "# print(x_val_neural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VgxG_HjT1Ws1"
   },
   "outputs": [],
   "source": [
    "# embed_dim = 32\n",
    "# lstm_out = 50\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_vocab,embed_dim,input_length = x_train_neural.shape[1]))\n",
    "# # model.add(SpatialDropout1D(0.4))\n",
    "# model.add(LSTM(lstm_out,dropout = 0.2,recurrent_dropout = 0.2))\n",
    "# model.add(Dense(1,activation = 'sigmoid'))\n",
    "# model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "# # print(x_train_neural.shape)\n",
    "# # print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ff1wcWIl1i54"
   },
   "outputs": [],
   "source": [
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-HVr7Sh9RaHv"
   },
   "outputs": [],
   "source": [
    "# model.fit(x_train_neural, y_train, epochs = 7, batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kr5mujppwA6B"
   },
   "outputs": [],
   "source": [
    "# likelihoods = model.predict(x_val_neural)\n",
    "# predictions_final = np.where(likelihoods < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UCUFHkdoyAsI"
   },
   "outputs": [],
   "source": [
    "# print(metrics.f1_score(y_val,predictions_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JXrKjh-J9Ov_"
   },
   "outputs": [],
   "source": [
    "# text = \"this is so stupid you so are off all you want, it's a simple fact. Assault rifles are select fire and the theoretical operation of a filed down sear is not\"\n",
    "# text = 'Seriously, youve fucking named the virtuous movement to end oppression after women, and the evil system that celebrates people after men, and you honestly expect me to believe that you arent inherently biased when thinking about this?'\n",
    "# text = 'unlike grabbing a woman that hurts by her pussy'\n",
    "# doc = nlp(text)\n",
    "\n",
    "# for token in doc:\n",
    "#   print(token.text, token.pos_, token.tag_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "50XLs6cFHHT9"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRrlybB3MMa_",
    "outputId": "55222464-e009-4d5c-e7e0-6d7531e16c92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_train = FeatureExtract(df_train)\n",
    "df_val = FeatureExtract(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r8oU1lI9N7nc"
   },
   "outputs": [],
   "source": [
    "x_train_text_features = df_train[[\"intensifier\",\"prp\",\"acomp\",\"abuse\",\"relcl\"]].values\n",
    "x_val_text_features = df_val[[\"intensifier\",\"prp\",\"acomp\",\"abuse\",\"relcl\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIGRiR8oOl_k",
    "outputId": "db864483-f43a-4331-8289-5d9fd22da34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1936, 5)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_text_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ExBVN66vRrjA"
   },
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "lstm_out = 50\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(max_vocab,embed_dim,input_length = x_train_neural.shape[1]))\n",
    "# model.add(SpatialDropout1D(0.4))\n",
    "model1.add(LSTM(lstm_out,dropout = 0.2,recurrent_dropout = 0.2))\n",
    "# model1.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(3,activation = 'relu',input_shape = (5,)))\n",
    "# model2.add(Dropout(0.2))\n",
    "\n",
    "merged_model = Concatenate()([model1.output,model2.output])\n",
    "z = Dense(10,activation = 'relu')(merged_model)\n",
    "z = Dense(1,activation = 'sigmoid')(z)\n",
    "\n",
    "model = Model(inputs=[model1.input, model2.input], outputs=z)\n",
    "# optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "# print(x_train_neural.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t-0XGlmSS1a",
    "outputId": "f6ac07f1-179c-4fae-9745-1cb5270afd60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedding_input (InputLayer)    [(None, 3033)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 3033, 32)     80000       embedding_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_input (InputLayer)        [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 50)           16600       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            18          dense_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 53)           0           lstm[0][0]                       \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           540         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            11          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 97,169\n",
      "Trainable params: 97,169\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLJqZ7GfBWrg",
    "outputId": "788034dc-7261-47ab-a219-7ebac50bbef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "61/61 - 259s - loss: 0.7827 - accuracy: 0.5165\n",
      "Epoch 2/5\n",
      "61/61 - 254s - loss: 0.6966 - accuracy: 0.5046\n",
      "Epoch 3/5\n",
      "61/61 - 255s - loss: 0.6893 - accuracy: 0.5305\n",
      "Epoch 4/5\n",
      "61/61 - 254s - loss: 0.6606 - accuracy: 0.6167\n",
      "Epoch 5/5\n",
      "61/61 - 258s - loss: 0.5318 - accuracy: 0.7495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9484f8a510>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train_neural,x_train_text_features], y_train, epochs = 5, batch_size = 32, verbose = 2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0w8QF44hDOs2"
   },
   "outputs": [],
   "source": [
    "likelihoods = model.predict([x_val_neural,x_val_text_features])\n",
    "predictions_final = np.where(likelihoods < 0.5, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyK-lmu7Jd47",
    "outputId": "3c94c2d5-cd41-4481-a774-530385be18f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7207792207792206\n",
      "(258, 1)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(y_val,predictions_final))\n",
    "print(predictions_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GHI3BeCa0Ovf"
   },
   "outputs": [],
   "source": [
    "val_data_id = df_val['id'].values\n",
    "predictions_final = predictions_final.flatten().tolist()\n",
    "pred_val = dict(zip(val_data_id, predictions_final))\n",
    "\n",
    "with open('/content/drive/MyDrive/prediction_out.json', 'w') as fp:\n",
    "    json.dump(pred_val,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gmbjXOs60pAb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Argument_assessment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
